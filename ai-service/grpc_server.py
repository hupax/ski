"""
gRPC server implementation for VideoAnalysisService
"""
import asyncio
from concurrent import futures

import grpc

# Import generated proto code
# Note: These will be generated by running:
# python3.12 -m grpc_tools.protoc -I../proto --python_out=./proto --grpc_python_out=./proto ../proto/video_analysis.proto
try:
    from proto import video_analysis_pb2
    from proto import video_analysis_pb2_grpc
except ImportError:
    print("ERROR: Proto files not generated. Please run:")
    print("python3.12 -m grpc_tools.protoc -I../proto --python_out=./proto --grpc_python_out=./proto ../proto/video_analysis.proto")
    raise

from config import Config
from video_processor import VideoProcessor
from models.factory import get_analyzer
from exceptions import VideoProcessingError, AIServiceError, ModelNotFoundError
from utils.logger import setup_logger

logger = setup_logger(__name__)


class VideoAnalysisServicer(video_analysis_pb2_grpc.VideoAnalysisServiceServicer):
    """Implementation of VideoAnalysisService"""

    def __init__(self):
        self.video_processor = VideoProcessor()
        logger.info("VideoAnalysisServicer initialized")

    def ProcessVideo(self, request, context):
        """
        Process video: FFmpeg slicing with sliding window

        Args:
            request: ProcessRequest
            context: gRPC context

        Returns:
            ProcessResponse with window file paths
        """
        try:
            session_id = request.session_id
            chunk_id = request.chunk_id
            video_path = request.video_path
            analysis_mode = request.analysis_mode
            window_size = request.window_size or Config.WINDOW_SIZE
            window_step = request.window_step or Config.WINDOW_STEP

            logger.info(f"ProcessVideo called: session={session_id}, chunk={chunk_id}, mode={analysis_mode}")

            # Handle different analysis modes
            if analysis_mode.lower() == "full":
                # For full mode, return the original video path
                logger.info("Full mode: returning original video path")
                return video_analysis_pb2.ProcessResponse(
                    window_paths=[video_path],
                    error=""
                )

            elif analysis_mode.lower() == "sliding_window":
                # Slice video into windows
                window_paths = self.video_processor.slice_video(
                    video_path=video_path,
                    session_id=session_id,
                    chunk_id=chunk_id,
                    window_size=window_size,
                    window_step=window_step
                )

                logger.info(f"ProcessVideo completed: {len(window_paths)} windows created")

                return video_analysis_pb2.ProcessResponse(
                    window_paths=window_paths,
                    error=""
                )

            else:
                error_msg = f"Unknown analysis mode: {analysis_mode}"
                logger.error(error_msg)
                return video_analysis_pb2.ProcessResponse(
                    window_paths=[],
                    error=error_msg
                )

        except VideoProcessingError as e:
            logger.error(f"ProcessVideo failed: {e}")
            return video_analysis_pb2.ProcessResponse(
                window_paths=[],
                error=str(e)
            )
        except Exception as e:
            logger.error(f"Unexpected error in ProcessVideo: {e}")
            return video_analysis_pb2.ProcessResponse(
                window_paths=[],
                error=f"Internal error: {e}"
            )

    def AnalyzeVideo(self, request, context):
        """
        Analyze video using AI API (streaming response)

        Args:
            request: AnalysisRequest
            context: gRPC context

        Yields:
            AnalysisResponse (streaming)
        """
        try:
            session_id = request.session_id
            window_index = request.window_index
            video_url = request.video_url
            ai_model = request.ai_model
            context_text = request.context
            start_offset = request.start_offset
            end_offset = request.end_offset

            logger.info(f"AnalyzeVideo called: session={session_id}, window={window_index}, model={ai_model}")
            logger.info(f"ðŸ“¥ [URL-TRACK] Received from core-service: session={session_id}, window={window_index}, videoUrl={video_url}")

            # Get analyzer
            try:
                analyzer = get_analyzer(ai_model)
            except ModelNotFoundError as e:
                logger.error(f"Model not found: {e}")
                yield video_analysis_pb2.AnalysisResponse(
                    session_id=session_id,
                    window_index=window_index,
                    content="",
                    is_final=True,
                    error=str(e)
                )
                return

            # Analyze video and stream results
            # Create a queue to bridge async generator to sync generator
            import queue
            import threading

            response_queue = queue.Queue()
            error_holder = []

            def run_async_analyzer():
                """Run async analyzer in a separate thread with event loop"""
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    async def analyze():
                        chunk_count = 0
                        try:
                            async for content_chunk in analyzer.analyze_video(
                                    video_url=video_url,
                                    context=context_text,
                                    session_id=session_id,
                                    window_index=window_index
                            ):
                                chunk_count += 1
                                response = video_analysis_pb2.AnalysisResponse(
                                    session_id=session_id,
                                    window_index=window_index,
                                    content=content_chunk,
                                    is_final=False,
                                    error=""
                                )
                                response_queue.put(('data', response))

                            # Send final message
                            logger.info(f"AnalyzeVideo completed: session={session_id}, window={window_index}, chunks={chunk_count}")
                            final_response = video_analysis_pb2.AnalysisResponse(
                                session_id=session_id,
                                window_index=window_index,
                                content="",
                                is_final=True,
                                error=""
                            )
                            response_queue.put(('data', final_response))
                        except Exception as e:
                            error_holder.append(e)
                            response_queue.put(('error', e))
                        finally:
                            response_queue.put(('done', None))

                    loop.run_until_complete(analyze())
                finally:
                    loop.close()

            # Start async analyzer in background thread
            analyzer_thread = threading.Thread(target=run_async_analyzer, daemon=True)
            analyzer_thread.start()

            # Yield responses from queue
            while True:
                msg_type, data = response_queue.get()
                if msg_type == 'done':
                    break
                elif msg_type == 'error':
                    raise data
                elif msg_type == 'data':
                    yield data

            analyzer_thread.join(timeout=5.0)

        except AIServiceError as e:
            logger.error(f"AnalyzeVideo failed: {e}")
            yield video_analysis_pb2.AnalysisResponse(
                session_id=request.session_id,
                window_index=request.window_index,
                content="",
                is_final=True,
                error=str(e)
            )
        except Exception as e:
            logger.error(f"Unexpected error in AnalyzeVideo: {e}")
            yield video_analysis_pb2.AnalysisResponse(
                session_id=request.session_id,
                window_index=request.window_index,
                content="",
                is_final=True,
                error=f"Internal error: {e}"
            )

    def ExtractTail(self, request, context):
        """
        Extract the last N seconds from a video

        Args:
            request: ExtractTailRequest
            context: gRPC context

        Returns:
            ExtractTailResponse with output file path
        """
        try:
            video_path = request.video_path
            output_path = request.output_path
            duration = request.duration

            logger.info(f"ExtractTail called: video={video_path}, duration={duration}s")

            # Extract tail using VideoProcessor
            result_path = self.video_processor.extract_tail(
                video_path=video_path,
                output_path=output_path,
                duration=duration
            )

            logger.info(f"ExtractTail completed: output={result_path}")

            return video_analysis_pb2.ExtractTailResponse(
                output_path=result_path,
                error=""
            )

        except VideoProcessingError as e:
            logger.error(f"ExtractTail failed: {e}")
            return video_analysis_pb2.ExtractTailResponse(
                output_path="",
                error=str(e)
            )
        except Exception as e:
            logger.error(f"Unexpected error in ExtractTail: {e}")
            return video_analysis_pb2.ExtractTailResponse(
                output_path="",
                error=f"Internal error: {e}"
            )

    def ConcatVideos(self, request, context):
        """
        Concatenate multiple videos into one

        Args:
            request: ConcatVideosRequest
            context: gRPC context

        Returns:
            ConcatVideosResponse with output file path
        """
        try:
            video_paths = list(request.video_paths)
            output_path = request.output_path

            logger.info(f"ConcatVideos called: {len(video_paths)} videos")

            # Concatenate using VideoProcessor
            result_path = self.video_processor.concat_videos(
                video_paths=video_paths,
                output_path=output_path
            )

            logger.info(f"ConcatVideos completed: output={result_path}")

            return video_analysis_pb2.ConcatVideosResponse(
                output_path=result_path,
                error=""
            )

        except VideoProcessingError as e:
            logger.error(f"ConcatVideos failed: {e}")
            return video_analysis_pb2.ConcatVideosResponse(
                output_path="",
                error=str(e)
            )
        except Exception as e:
            logger.error(f"Unexpected error in ConcatVideos: {e}")
            return video_analysis_pb2.ConcatVideosResponse(
                output_path="",
                error=f"Internal error: {e}"
            )


def serve():
    """Start gRPC server"""
    try:
        # Create server with thread pool
        server = grpc.server(
            futures.ThreadPoolExecutor(max_workers=Config.GRPC_WORKERS),
            options=[
                ('grpc.max_send_message_length', Config.GRPC_MAX_MESSAGE_LENGTH),
                ('grpc.max_receive_message_length', Config.GRPC_MAX_MESSAGE_LENGTH)
            ]
        )

        # Add service
        video_analysis_pb2_grpc.add_VideoAnalysisServiceServicer_to_server(
            VideoAnalysisServicer(), server
        )

        # Bind port
        port = Config.GRPC_PORT
        server.add_insecure_port(f'[::]:{port}')

        # Start server
        server.start()
        logger.info(f"gRPC server started on port {port}")

        # Wait for termination
        server.wait_for_termination()

    except KeyboardInterrupt:
        logger.info("Received shutdown signal")
    except Exception as e:
        logger.error(f"Server error: {e}")
        raise


if __name__ == "__main__":
    serve()
